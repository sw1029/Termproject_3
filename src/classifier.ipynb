{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5490c46-655b-4adc-b6b9-4216719989a1",
   "metadata": {
    "id": "b5490c46-655b-4adc-b6b9-4216719989a1"
   },
   "source": [
    "# dnotitia/Llama-DNA-1.0-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kax2rx_sM0a2",
    "outputId": "29f89df0-ceba-481e-82d7-997a56bf516a"
   },
   "id": "Kax2rx_sM0a2",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bitsandbytes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3VIR8iosVBX",
    "outputId": "131cc9bd-5d6b-42fc-d005-ae2dbd6a6539"
   },
   "id": "r3VIR8iosVBX",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b2224-7543-4116-90d9-b65c406bbc27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "253b2224-7543-4116-90d9-b65c406bbc27",
    "outputId": "e60cdfb8-2617-4263-fb2b-ca67f469efc0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# 1. 모델 및 토크나이저 로드\n",
    "model_name = \"dnotitia/Llama-DNA-1.0-8B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                # 4-bit 양자화\n",
    "    bnb_4bit_use_double_quant=True,   # 2단계 양자화 사용 (효율성 향상)\n",
    "    bnb_4bit_quant_type=\"nf4\",        # 양자화 타입 (nf4 추천)\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 연산 dtype (bf16 또는 float16)\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,   # 양자화 config 전달\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "categories = {\n",
    "    0: \"졸업요건\",\n",
    "    1: \"학교 공지사항\",\n",
    "    2: \"학사일정\",\n",
    "    3: \"식단 안내\",\n",
    "    4: \"통학/셔틀 버스\"\n",
    "}\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def classify_query(user_query):\n",
    "    \"\"\"\n",
    "    사용자 질의를 입력받아 5가지 카테고리 중 하나로 분류합니다.\n",
    "    실패 시 무작위(0~4)로 fallback하여 절대 실패하지 않습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"다음은 사용자 질문과 관련된 카테고리 목록입니다:\n",
    "0: 졸업요건 (예: 졸업까지 몇 학점을 들어야 하나요?)\n",
    "1: 학교 공지사항 (예: 이번에 올라온 공지사항 어디서 볼 수 있어요?)\n",
    "2: 학사일정 (예: 이번 학기 수강신청은 언제 시작하나요?)\n",
    "3: 식단 안내 (예: 오늘 학식 뭐 나와요?)\n",
    "4: 통학/셔틀 버스 (예: 다음주에 셔틀버스는 정상 운행하나요?)\n",
    "\n",
    "사용자 질문: \"{user_query}\"\n",
    "위 질문은 어떤 카테고리에 가장 적합한가요? 숫자 레이블만 대답해주세요 (0, 1, 2, 3, 4 중 하나).\n",
    "\n",
    "가장 적합한 카테고리 번호: \"\"\"\n",
    "\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=5,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    response_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "    try:\n",
    "        predicted_label_str = ''.join(filter(str.isdigit, response_text))\n",
    "        if predicted_label_str:\n",
    "            predicted_label = int(predicted_label_str[0])\n",
    "            if predicted_label in categories:\n",
    "                return predicted_label, categories[predicted_label]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    category_examples = {\n",
    "        0: \"졸업 요건, 졸업 학점, 졸업 논문, 졸업 자격, 졸업 인증, 유예 신청, 졸업 필수 조건\",\n",
    "        1: \"학교 공지사항, 안내문, 공고, 공지 업데이트, 휴강 안내, 장학금 공지, 긴급 알림\",\n",
    "        2: \"수강 신청, 시험 기간, 성적 발표, 개강일, 종강일, 학사 일정, 수업 일정, 등록 일정\",\n",
    "        3: \"학식, 학생 식당, 식단표, 조식, 중식, 석식, 오늘 메뉴, 급식 시간, 식단 운영\",\n",
    "        4: \"셔틀버스, 통학버스, 운행 시간표, 버스 노선, 정류장 위치, 셔틀 예약, 통학 교통\"\n",
    "    }\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    best_label = None\n",
    "    for label, example in category_examples.items():\n",
    "        score = difflib.SequenceMatcher(None, user_query, example).ratio()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_label = label\n",
    "\n",
    "    return best_label, categories[best_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421ce51-b4e7-44a1-8dfb-530191149afa",
   "metadata": {
    "id": "e421ce51-b4e7-44a1-8dfb-530191149afa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 기존 classify_query 함수 사용 (import 되어 있다고 가정)\n",
    "\n",
    "# 1. 입력 JSON 파일 로드\n",
    "with open(\"/content/drive/MyDrive/classifier_questions_only.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    questions_data = json.load(f)\n",
    "\n",
    "# 2. 결과 저장 리스트\n",
    "results = []\n",
    "\n",
    "# 3. 각 질문에 대해 분류 수행\n",
    "for item in tqdm(questions_data):\n",
    "    question = item[\"question\"]\n",
    "    label, _ = classify_query(question)  # VARCO 모델 사용\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "# 4. 결과 JSON 파일 저장\n",
    "with open(\"cls_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ 분류 결과가 classified_results.json 파일로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
