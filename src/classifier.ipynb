{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5490c46-655b-4adc-b6b9-4216719989a1",
   "metadata": {
    "id": "b5490c46-655b-4adc-b6b9-4216719989a1"
   },
   "source": [
    "# dnotitia/Llama-DNA-1.0-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433a10dd2a47b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\term\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes accelerate chardet charset-normalizer jupyter\n",
    "!pip install torch==2.5.1+cu121 torchvision==0.18.1+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
    "!pip install transformers\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253b2224-7543-4116-90d9-b65c406bbc27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T11:39:01.621368Z",
     "start_time": "2025-06-07T11:38:59.776684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "253b2224-7543-4116-90d9-b65c406bbc27",
    "outputId": "e60cdfb8-2617-4263-fb2b-ca67f469efc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\term\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\anaconda3\\envs\\term\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. \ubaa8\ub378 \ubc0f \ud1a0\ud06c\ub098\uc774\uc800 \ub85c\ub4dc\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdnotitia/Llama-DNA-1.0-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m \u001b[43mBitsAndBytesConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# 4-bit \uc591\uc790\ud654\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_use_double_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 2\ub2e8\uacc4 \uc591\uc790\ud654 \uc0ac\uc6a9 (\ud6a8\uc728\uc131 \ud5a5\uc0c1)\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_quant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnf4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \uc591\uc790\ud654 \ud0c0\uc785 (nf4 \ucd94\ucc9c)\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \uc5f0\uc0b0 dtype (bf16 \ub610\ub294 float16)\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     16\u001b[0m     model_name,\n\u001b[0;32m     17\u001b[0m     quantization_config\u001b[38;5;241m=\u001b[39mbnb_config,   \u001b[38;5;66;03m# \uc591\uc790\ud654 config \uc804\ub2ec\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\term\\lib\\site-packages\\transformers\\utils\\quantization_config.py:508\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.__init__\u001b[1;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    506\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnused kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. These kwargs are not used in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\term\\lib\\site-packages\\transformers\\utils\\quantization_config.py:566\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.post_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_4bit_use_double_quant, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbnb_4bit_use_double_quant must be a boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_in_4bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbitsandbytes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m ):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4 bit quantization requires bitsandbytes>=0.39.0 - please upgrade your bitsandbytes version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\term\\lib\\importlib\\metadata\\__init__.py:996\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m    990\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \n\u001b[0;32m    992\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\term\\lib\\importlib\\metadata\\__init__.py:969\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    964\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \n\u001b[0;32m    966\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\term\\lib\\importlib\\metadata\\__init__.py:548\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# 1. \ubaa8\ub378 \ubc0f \ud1a0\ud06c\ub098\uc774\uc800 \ub85c\ub4dc\n",
    "model_name = \"dnotitia/Llama-DNA-1.0-8B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                # 4-bit \uc591\uc790\ud654\n",
    "    bnb_4bit_use_double_quant=True,   # 2\ub2e8\uacc4 \uc591\uc790\ud654 \uc0ac\uc6a9 (\ud6a8\uc728\uc131 \ud5a5\uc0c1)\n",
    "    bnb_4bit_quant_type=\"nf4\",        # \uc591\uc790\ud654 \ud0c0\uc785 (nf4 \ucd94\ucc9c)\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # \uc5f0\uc0b0 dtype (bf16 \ub610\ub294 float16)\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,   # \uc591\uc790\ud654 config \uc804\ub2ec\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "\n",
    "categories = {\n",
    "    0: \"\uc878\uc5c5\uc694\uac74\",\n",
    "    1: \"\ud559\uad50 \uacf5\uc9c0\uc0ac\ud56d\",\n",
    "    2: \"\ud559\uc0ac\uc77c\uc815\",\n",
    "    3: \"\uc2dd\ub2e8 \uc548\ub0b4\",\n",
    "    4: \"\ud1b5\ud559/\uc154\ud2c0 \ubc84\uc2a4\"\n",
    "}\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def classify_query(user_query):\n",
    "    \"\"\"\n",
    "    \uc0ac\uc6a9\uc790 \uc9c8\uc758\ub97c \uc785\ub825\ubc1b\uc544 5\uac00\uc9c0 \uce74\ud14c\uace0\ub9ac \uc911 \ud558\ub098\ub85c \ubd84\ub958\ud569\ub2c8\ub2e4.\n",
    "    \uc2e4\ud328 \uc2dc \ubb34\uc791\uc704(0~4)\ub85c fallback\ud558\uc5ec \uc808\ub300 \uc2e4\ud328\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\ub2e4\uc74c\uc740 \uc0ac\uc6a9\uc790 \uc9c8\ubb38\uacfc \uad00\ub828\ub41c \uce74\ud14c\uace0\ub9ac \ubaa9\ub85d\uc785\ub2c8\ub2e4:\n",
    "0: \uc878\uc5c5\uc694\uac74 (\uc608: \uc878\uc5c5\uae4c\uc9c0 \uba87 \ud559\uc810\uc744 \ub4e4\uc5b4\uc57c \ud558\ub098\uc694?)\n",
    "1: \ud559\uad50 \uacf5\uc9c0\uc0ac\ud56d (\uc608: \uc774\ubc88\uc5d0 \uc62c\ub77c\uc628 \uacf5\uc9c0\uc0ac\ud56d \uc5b4\ub514\uc11c \ubcfc \uc218 \uc788\uc5b4\uc694?)\n",
    "2: \ud559\uc0ac\uc77c\uc815 (\uc608: \uc774\ubc88 \ud559\uae30 \uc218\uac15\uc2e0\uccad\uc740 \uc5b8\uc81c \uc2dc\uc791\ud558\ub098\uc694?)\n",
    "3: \uc2dd\ub2e8 \uc548\ub0b4 (\uc608: \uc624\ub298 \ud559\uc2dd \ubb50 \ub098\uc640\uc694?)\n",
    "4: \ud1b5\ud559/\uc154\ud2c0 \ubc84\uc2a4 (\uc608: \ub2e4\uc74c\uc8fc\uc5d0 \uc154\ud2c0\ubc84\uc2a4\ub294 \uc815\uc0c1 \uc6b4\ud589\ud558\ub098\uc694?)\n",
    "\n",
    "\uc0ac\uc6a9\uc790 \uc9c8\ubb38: \"{user_query}\"\n",
    "\uc704 \uc9c8\ubb38\uc740 \uc5b4\ub5a4 \uce74\ud14c\uace0\ub9ac\uc5d0 \uac00\uc7a5 \uc801\ud569\ud55c\uac00\uc694? \uc22b\uc790 \ub808\uc774\ube14\ub9cc \ub300\ub2f5\ud574\uc8fc\uc138\uc694 (0, 1, 2, 3, 4 \uc911 \ud558\ub098).\n",
    "\n",
    "\uac00\uc7a5 \uc801\ud569\ud55c \uce74\ud14c\uace0\ub9ac \ubc88\ud638: \"\"\"\n",
    "\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=5,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    response_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "    try:\n",
    "        predicted_label_str = ''.join(filter(str.isdigit, response_text))\n",
    "        if predicted_label_str:\n",
    "            predicted_label = int(predicted_label_str[0])\n",
    "            if predicted_label in categories:\n",
    "                return predicted_label, categories[predicted_label]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    category_examples = {\n",
    "        0: \"\uc878\uc5c5 \uc694\uac74, \uc878\uc5c5 \ud559\uc810, \uc878\uc5c5 \ub17c\ubb38, \uc878\uc5c5 \uc790\uaca9, \uc878\uc5c5 \uc778\uc99d, \uc720\uc608 \uc2e0\uccad, \uc878\uc5c5 \ud544\uc218 \uc870\uac74\",\n",
    "        1: \"\ud559\uad50 \uacf5\uc9c0\uc0ac\ud56d, \uc548\ub0b4\ubb38, \uacf5\uace0, \uacf5\uc9c0 \uc5c5\ub370\uc774\ud2b8, \ud734\uac15 \uc548\ub0b4, \uc7a5\ud559\uae08 \uacf5\uc9c0, \uae34\uae09 \uc54c\ub9bc\",\n",
    "        2: \"\uc218\uac15 \uc2e0\uccad, \uc2dc\ud5d8 \uae30\uac04, \uc131\uc801 \ubc1c\ud45c, \uac1c\uac15\uc77c, \uc885\uac15\uc77c, \ud559\uc0ac \uc77c\uc815, \uc218\uc5c5 \uc77c\uc815, \ub4f1\ub85d \uc77c\uc815\",\n",
    "        3: \"\ud559\uc2dd, \ud559\uc0dd \uc2dd\ub2f9, \uc2dd\ub2e8\ud45c, \uc870\uc2dd, \uc911\uc2dd, \uc11d\uc2dd, \uc624\ub298 \uba54\ub274, \uae09\uc2dd \uc2dc\uac04, \uc2dd\ub2e8 \uc6b4\uc601\",\n",
    "        4: \"\uc154\ud2c0\ubc84\uc2a4, \ud1b5\ud559\ubc84\uc2a4, \uc6b4\ud589 \uc2dc\uac04\ud45c, \ubc84\uc2a4 \ub178\uc120, \uc815\ub958\uc7a5 \uc704\uce58, \uc154\ud2c0 \uc608\uc57d, \ud1b5\ud559 \uad50\ud1b5\"\n",
    "    }\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    best_label = None\n",
    "    for label, example in category_examples.items():\n",
    "        score = difflib.SequenceMatcher(None, user_query, example).ratio()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_label = label\n",
    "\n",
    "    return best_label, categories[best_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421ce51-b4e7-44a1-8dfb-530191149afa",
   "metadata": {
    "id": "e421ce51-b4e7-44a1-8dfb-530191149afa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data/question directory relative to this notebook\n",
    "base_dir = Path('../data/question') if Path('../data/question').exists() else Path('data/question')\n",
    "output_dir = Path('../outputs') if Path('../outputs').exists() else Path('outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for path in base_dir.glob('*.json'):\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        questions_data = json.load(f)\n",
    "    results = []\n",
    "    for item in tqdm(questions_data, desc=path.name):\n",
    "        question = item['question']\n",
    "        label, _ = classify_query(question)  # VARCO \ubaa8\ub378 \uc0ac\uc6a9\n",
    "        results.append({'question': question, 'label': label})\n",
    "    out_file = output_dir / f\"{path.stem}_output.json\"\n",
    "    with out_file.open('w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f'\u2705 {out_file} \uc800\uc7a5 \uc644\ub8cc')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
