{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7d92edb9231de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3208001c9d44499897ffdd99e3fbacab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435536af941245baae0bfd362be289f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627d336892bb4e87a6f2ca76abc538c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfafff227fa4733ada974a36e1390ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1168d4798154e78a4c28647b427714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7323a0877ed43e098d1e3121f5ace56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d130c5b60a48e6a24e90ea7a6c8e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3300b1817c4445993c77d6a47152d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36589e9a7aed4093a3ece86eb5883a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/36.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4278dba3384b83a11f14dbb34ff43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd4376febd5427caffd7ed457852177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37c54c71b334f6182f6ab386d668697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c3399f4c494fb09105e70140308aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa1ab3de23a428399e977c8d95a3875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4ccca6a76f4cbeab7f5d173af49334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdae273d20b48b9af470bc9c2a4f906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/3.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c506facbf80340a68bdd24231d72d217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef071f092764ef7b78b298eb0e8a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "카테고리 분류용 Llama-DNA 8B 모델 로드 & 추론 스크립트\n",
    "- GPU + bitsandbytes(nf4) 지원 시: 4-bit 양자화 로드\n",
    "- 그 외 환경(Windows CPU 등): 일반 float32/bfloat16 로드\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import difflib\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from utils.config import settings\n",
    "\n",
    "# (선택) tqdm IProgress 경고 끄기\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. 하드웨어 & 라이브러리 호환성 감지\n",
    "# ---------------------------------------------------------------------\n",
    "USE_4BIT = False\n",
    "bnb_config = None\n",
    "try:\n",
    "    # bitsandbytes & GPU 가 모두 준비된 경우에만 4-bit 사용\n",
    "    from transformers import BitsAndBytesConfig\n",
    "    import bitsandbytes as bnb\n",
    "\n",
    "    if torch.cuda.is_available():  # GPU 존재\n",
    "        # GPU compute capability(예: (8,0))가 7.x 이상이면 안전\n",
    "        major_cc, _ = torch.cuda.get_device_capability(0)\n",
    "        if major_cc >= 7:\n",
    "            USE_4BIT = True\n",
    "except (ImportError, RuntimeError, AttributeError, ValueError):\n",
    "    # bitsandbytes 미설치 또는 CPU-only -> 4bit 비활성\n",
    "    USE_4BIT = False\n",
    "\n",
    "if USE_4BIT:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16   # bf16 계산\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. 모델 및 토크나이저 로드\n",
    "# ---------------------------------------------------------------------\n",
    "MODEL_NAME = settings.classifier_model_name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, force_download=False)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"device_map\": \"auto\" if torch.cuda.is_available() else {\"\": \"cpu\"}\n",
    "}\n",
    "if bnb_config is not None:\n",
    "    model_kwargs[\"quantization_config\"] = bnb_config\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    force_download=False,\n",
    "    **model_kwargs\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. 카테고리 정의\n",
    "# ---------------------------------------------------------------------\n",
    "categories = {\n",
    "    0: \"졸업요건\",\n",
    "    1: \"학교 공지사항\",\n",
    "    2: \"학사일정\",\n",
    "    3: \"식단 안내\",\n",
    "    4: \"통학/셔틀 버스\"\n",
    "}\n",
    "\n",
    "# 예시 문장(간단한 룰-베이스 fallback용)\n",
    "category_examples = {\n",
    "    0: \"졸업 요건, 졸업 학점, 졸업 논문, 졸업 자격, 유예 신청\",\n",
    "    1: \"학교 공지사항, 안내문, 휴강 안내, 장학금 공지, 긴급 알림\",\n",
    "    2: \"수강 신청, 시험 기간, 성적 발표, 개강일, 종강일, 학사 일정\",\n",
    "    3: \"학식, 학생 식당, 식단표, 오늘 메뉴, 급식 시간\",\n",
    "    4: \"셔틀버스, 통학버스, 버스 시간표, 노선, 정류장 위치\"\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4. 분류 함수\n",
    "# ---------------------------------------------------------------------\n",
    "def classify_query(user_query: str):\n",
    "    \"\"\"\n",
    "    • LLM + 프롬프트를 이용해 5개 카테고리 중 하나 예측\n",
    "    • 파싱 실패 시 간단한 문자열 유사도로 fallback\n",
    "    • 절대 실패하지 않음 (항상 0~4 반환)\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"다음은 사용자 질문과 관련된 카테고리 목록입니다:\n",
    "0: 졸업요건\n",
    "1: 학교 공지사항\n",
    "2: 학사일정\n",
    "3: 식단 안내\n",
    "4: 통학/셔틀 버스\n",
    "\n",
    "사용자 질문: \"{user_query}\"\n",
    "위 질문은 어떤 카테고리에 가장 적합한가요? 숫자 레이블(0~4)만 답하세요.\n",
    "\n",
    "카테고리 번호:\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        do_sample=False\n",
    "    )\n",
    "    response_text = tokenizer.decode(\n",
    "        outputs[0][inputs.input_ids.shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n",
    "\n",
    "    # 숫자 파싱 시도\n",
    "    digits = ''.join(filter(str.isdigit, response_text))\n",
    "    if digits:\n",
    "        label = int(digits[0])\n",
    "        if label in categories:\n",
    "            return label, categories[label]\n",
    "\n",
    "    # ----------------- fallback: 문자열 유사도 -----------------\n",
    "    best_score, best_label = 0.0, 0\n",
    "    for label, example in category_examples.items():\n",
    "        score = difflib.SequenceMatcher(None, user_query, example).ratio()\n",
    "        if score > best_score:\n",
    "            best_score, best_label = score, label\n",
    "\n",
    "    return best_label, categories[best_label]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5. 사용 예시\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    q = \"오늘 학식 뭐 나와?\"\n",
    "    lbl, lbl_txt = classify_query(q)\n",
    "    print(f\"입력: {q}\\n예측: {lbl} ({lbl_txt})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421ce51-b4e7-44a1-8dfb-530191149afa",
   "metadata": {
    "id": "e421ce51-b4e7-44a1-8dfb-530191149afa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data/question directory relative to this notebook\n",
    "base_dir = Path('../data/question') if Path('../data/question').exists() else Path('data/question')\n",
    "output_dir = Path('../outputs') if Path('../outputs').exists() else Path('outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for path in base_dir.glob('*.json'):\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        questions_data = json.load(f)\n",
    "    results = []\n",
    "    for item in tqdm(questions_data, desc=path.name):\n",
    "        question = item['question']\n",
    "        label, _ = classify_query(question)  # VARCO 모델 사용\n",
    "        results.append({'question': question, 'label': label})\n",
    "    out_file = output_dir / f\"{path.stem}_output.json\"\n",
    "    with out_file.open('w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    print(f'✅ {out_file} 저장 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51ec230b1136b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = '../models/classifier'\n",
    "import os\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "print(f'Model and Tokenizer saved to {MODEL_SAVE_PATH}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
